{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mixed precision enabled.\n",
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "import tensorflow as tf\n",
    "from collections import deque\n",
    "import time\n",
    "\n",
    "# Ensure TensorFlow uses mixed precision for faster computation on supported GPUs\n",
    "try:\n",
    "    from tensorflow.keras import mixed_precision\n",
    "    mixed_precision.set_global_policy('mixed_float16')\n",
    "    print(\"Mixed precision enabled.\")\n",
    "except ImportError:\n",
    "    print(\"Mixed precision not available.\")\n",
    "\n",
    "# Define actions\n",
    "actions = np.array(['hello', 'father', 'mother', 'deaf', 'no', 'love',\n",
    "                   \"help\", \"please\", \"more\", \"thankyou\"])\n",
    "\n",
    "# Build the model architecture\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv1D(64, kernel_size=3, activation='relu', padding='same', input_shape=(30, 1662)),\n",
    "    tf.keras.layers.MaxPooling1D(pool_size=2),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "\n",
    "    tf.keras.layers.Conv1D(128, kernel_size=3, activation='relu', padding='same'),\n",
    "    tf.keras.layers.MaxPooling1D(pool_size=2),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128, return_sequences=True)),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Activation('relu'),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.GRU(256, return_sequences=True)),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Activation('relu'),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(512, return_sequences=True)),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Activation('relu'),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "\n",
    "    tf.keras.layers.LSTM(256, return_sequences=True),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Activation('relu'),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "\n",
    "    tf.keras.layers.LSTM(128, return_sequences=False),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Activation('relu'),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(actions.shape[0], activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Load the weights\n",
    "model.load_weights('./models/LSTM_refined2.h5')\n",
    "\n",
    "# Initialize Mediapipe\n",
    "mp_holistic = mp.solutions.holistic\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Function to detect and process the image\n",
    "def mediapipe_detection(image, model):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB\n",
    "    image.flags.writeable = False                   # Improve performance\n",
    "    results = model.process(image)                  # Make prediction\n",
    "    image.flags.writeable = True                    # Restore image\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR) # Convert back to BGR\n",
    "    return image, results\n",
    "\n",
    "# Function to extract keypoints\n",
    "def extract_keypoints(results):\n",
    "    pose = np.array([[res.x, res.y, res.z, res.visibility] for res in results.pose_landmarks.landmark]).flatten() if results.pose_landmarks else np.zeros(33 * 4)\n",
    "    face = np.array([[res.x, res.y, res.z] for res in results.face_landmarks.landmark]).flatten() if results.face_landmarks else np.zeros(468 * 3)\n",
    "    lh = np.array([[res.x, res.y, res.z] for res in results.left_hand_landmarks.landmark]).flatten() if results.left_hand_landmarks else np.zeros(21 * 3)\n",
    "    rh = np.array([[res.x, res.y, res.z] for res in results.right_hand_landmarks.landmark]).flatten() if results.right_hand_landmarks else np.zeros(21 * 3)\n",
    "    return np.concatenate([pose, face, lh, rh])\n",
    "\n",
    "# Initialize variables\n",
    "sequence = deque(maxlen=30)\n",
    "sentence = []\n",
    "threshold = 0.8\n",
    "previous_action = None\n",
    "\n",
    "# Initialize video capture\n",
    "cap = cv2.VideoCapture('./uploads/uploaded_video.mp4')\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open video.\")\n",
    "    exit()\n",
    "\n",
    "# Set target FPS\n",
    "target_fps = 5\n",
    "video_fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "frame_interval = max(int(video_fps / target_fps), 1)\n",
    "frame_count = 0\n",
    "\n",
    "# Verify GPU usage\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "\n",
    "# Define TensorFlow prediction function with @tf.function for optimization\n",
    "@tf.function\n",
    "def predict_action(input_sequence):\n",
    "    return model(input_sequence, training=False)\n",
    "\n",
    "# Open file to write predictions\n",
    "with open('predictions.txt', 'w') as f:\n",
    "    with mp_holistic.Holistic(min_detection_confidence=0.8, min_tracking_confidence=0.8, static_image_mode=False) as holistic:\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            if frame_count % frame_interval != 0:\n",
    "                frame_count += 1\n",
    "                continue\n",
    "\n",
    "            frame = cv2.resize(frame, (640, 360))\n",
    "            image, results = mediapipe_detection(frame, holistic)\n",
    "\n",
    "            # Extract keypoints\n",
    "            keypoints = extract_keypoints(results)\n",
    "            sequence.append(keypoints)\n",
    "\n",
    "            if len(sequence) == 30:\n",
    "                # Convert sequence to numpy array and expand dimensions for batch\n",
    "                input_sequence = np.expand_dims(np.array(sequence), axis=0).astype(np.float16)  # Use float16 if mixed precision\n",
    "\n",
    "                # Make prediction\n",
    "                res = predict_action(input_sequence)[0].numpy()\n",
    "\n",
    "                # Decode prediction\n",
    "                action = actions[np.argmax(res)]\n",
    "                confidence = res[np.argmax(res)]\n",
    "\n",
    "                if confidence > threshold and action != previous_action:\n",
    "                    current_frame = int(cap.get(cv2.CAP_PROP_POS_FRAMES))\n",
    "                    f.write(f\"Frame {current_frame}: {action}, Confidence: {confidence}\\n\")\n",
    "                    previous_action = action\n",
    "\n",
    "                    if not sentence or action != sentence[-1]:\n",
    "                        sentence.append(action)\n",
    "\n",
    "                if len(sentence) > 5:\n",
    "                    sentence = sentence[-5:]\n",
    "\n",
    "            frame_count += 1\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
